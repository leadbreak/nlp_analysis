{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 00. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, gzip, pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from konlpy.tag import *\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 01. Data Load & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"newszum_train_data.csv\")\n",
    "test = pd.read_csv(\"newszum_test_data.csv\")\n",
    "data = pd.concat([train, test], ignore_index=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.category.hist(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.category.hist(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.category.hist(figsize=(20,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.title.str.len().hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cleanBody.str.len().hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 02. Tokenizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df = 2\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "train_morph = []\n",
    "for i in range(len(train)):\n",
    "    train_morph.append(\" \".join([x for x in okt.nouns(train['title'][i]) if len(x) > 1]))\n",
    "    \n",
    "test_morph = []\n",
    "for i in range(len(test)):\n",
    "    test_morph.append(\" \".join([x for x in okt.nouns(test['title'][i]) if len(x) > 1]))\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word',       \n",
    "                        min_df=min_df,   # 특정 횟수 이상 언급된 것만 따로                      \n",
    "                        max_features=50000,             \n",
    "                        )\n",
    "\n",
    "train_vectorized = vectorizer.fit_transform(train_morph)\n",
    "test_vectorized = vectorizer.transform(test_morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exmaple\n",
    "T_words = pd.DataFrame(train_vectorized.toarray(), columns=vectorizer.get_feature_names())\n",
    "T_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_len = len(vectorizer.get_feature_names())\n",
    "T_train = pd.DataFrame(train_vectorized.toarray(), columns=[i for i in range(T_len)])\n",
    "T_test = pd.DataFrame(test_vectorized.toarray(), columns=[i for i in range(T_len)])\n",
    "\n",
    "T_train.shape, T_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Body Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_df = 5\n",
    "\n",
    "okt = Okt()\n",
    "\n",
    "train_morph = []\n",
    "for i in range(len(train)):\n",
    "    train_morph.append(\" \".join([x for x in okt.nouns(train['cleanBody'][i]) if len(x) > 1]))\n",
    "\n",
    "test_morph = []\n",
    "for i in range(len(test)):\n",
    "    test_morph.append(\" \".join([x for x in okt.nouns(test['cleanBody'][i]) if len(x) > 1]))\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word',       \n",
    "                        min_df=min_df,   # 특정 횟수 이상 언급된 것만 따로                      \n",
    "                        max_features=50000,             \n",
    "                        )\n",
    "\n",
    "train_vectorized = vectorizer.fit_transform(train_morph)\n",
    "test_vectorized = vectorizer.transform(test_morph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>가가</th>\n",
       "      <th>가게</th>\n",
       "      <th>가격</th>\n",
       "      <th>가결</th>\n",
       "      <th>가구</th>\n",
       "      <th>가기</th>\n",
       "      <th>가까이</th>\n",
       "      <th>가늠</th>\n",
       "      <th>가능</th>\n",
       "      <th>가능성</th>\n",
       "      <th>...</th>\n",
       "      <th>흥행</th>\n",
       "      <th>희망</th>\n",
       "      <th>희망이</th>\n",
       "      <th>희생</th>\n",
       "      <th>흰색</th>\n",
       "      <th>히데</th>\n",
       "      <th>히어로</th>\n",
       "      <th>히어로즈</th>\n",
       "      <th>히트</th>\n",
       "      <th>힐링</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026415</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2196 rows × 6702 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       가가   가게   가격   가결   가구   가기  가까이   가늠   가능       가능성  ...   흥행   희망  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...       ...  ...  ...  ...   \n",
       "2191  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "2192  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.026415  ...  0.0  0.0   \n",
       "2193  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "2194  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "2195  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.000000  ...  0.0  0.0   \n",
       "\n",
       "      희망이        희생   흰색   히데  히어로  히어로즈   히트   힐링  \n",
       "0     0.0  0.105369  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "1     0.0  0.281241  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "2     0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "3     0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "4     0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "...   ...       ...  ...  ...  ...   ...  ...  ...  \n",
       "2191  0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "2192  0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "2193  0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "2194  0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "2195  0.0  0.000000  0.0  0.0  0.0   0.0  0.0  0.0  \n",
       "\n",
       "[2196 rows x 6702 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# example\n",
    "B_words = pd.DataFrame(train_vectorized.toarray(), columns=vectorizer.get_feature_names())\n",
    "B_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((2196, 6702), (942, 6702))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_len = len(vectorizer.get_feature_names())\n",
    "B_train = pd.DataFrame(train_vectorized.toarray(), columns=[i+T_len for i in range(B_len)])\n",
    "B_test = pd.DataFrame(test_vectorized.toarray(), columns=[i+T_len for i in range(B_len)])\n",
    "\n",
    "B_train.shape, B_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'international': 0,\n",
       " 'economy': 1,\n",
       " 'society': 2,\n",
       " 'sport': 3,\n",
       " 'it': 4,\n",
       " 'politics': 5,\n",
       " 'entertain': 6,\n",
       " 'culture': 7}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train.category.unique()\n",
    "\n",
    "labels_dict = {}\n",
    "for i in range(len(labels)) :\n",
    "    labels_dict[labels[i]] = i\n",
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_train = train['category'].map(lambda x : labels_dict[x])\n",
    "L_test = test['category'].map(lambda x : labels_dict[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>9080</th>\n",
       "      <th>9081</th>\n",
       "      <th>9082</th>\n",
       "      <th>9083</th>\n",
       "      <th>9084</th>\n",
       "      <th>9085</th>\n",
       "      <th>9086</th>\n",
       "      <th>9087</th>\n",
       "      <th>9088</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.105369</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.281241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2196 rows × 9090 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  9080  9081  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   \n",
       "2191  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2192  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2193  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2194  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "2195  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   \n",
       "\n",
       "          9082  9083  9084  9085  9086  9087  9088  category  \n",
       "0     0.105369   0.0   0.0   0.0   0.0   0.0   0.0         0  \n",
       "1     0.281241   0.0   0.0   0.0   0.0   0.0   0.0         0  \n",
       "2     0.000000   0.0   0.0   0.0   0.0   0.0   0.0         1  \n",
       "3     0.000000   0.0   0.0   0.0   0.0   0.0   0.0         1  \n",
       "4     0.000000   0.0   0.0   0.0   0.0   0.0   0.0         2  \n",
       "...        ...   ...   ...   ...   ...   ...   ...       ...  \n",
       "2191  0.000000   0.0   0.0   0.0   0.0   0.0   0.0         6  \n",
       "2192  0.000000   0.0   0.0   0.0   0.0   0.0   0.0         2  \n",
       "2193  0.000000   0.0   0.0   0.0   0.0   0.0   0.0         2  \n",
       "2194  0.000000   0.0   0.0   0.0   0.0   0.0   0.0         6  \n",
       "2195  0.000000   0.0   0.0   0.0   0.0   0.0   0.0         5  \n",
       "\n",
       "[2196 rows x 9090 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([T_train, B_train, L_train], axis=1)\n",
    "df_test = pd.concat([T_test, B_test, L_test], axis=1)\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 03. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Base Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.826963906581741 0.8598726114649682 0.8354564755838642\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X, y = df_train.iloc[:,:-1], df_train.iloc[:,-1]\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "lr = LogisticRegression()\n",
    "xgb = XGBClassifier()\n",
    "\n",
    "rf.fit(X, y)\n",
    "lr.fit(X, y)\n",
    "xgb.fit(X, y)\n",
    "\n",
    "pred1 = rf.predict(df_test.iloc[:,:-1])\n",
    "pred2 = lr.predict(df_test.iloc[:,:-1])\n",
    "pred3 = xgb.predict(df_test.iloc[:,:-1])\n",
    "\n",
    "score1 = accuracy_score(df_test.iloc[:,-1], pred1)\n",
    "score2 = accuracy_score(df_test.iloc[:,-1], pred2)\n",
    "score3 = accuracy_score(df_test.iloc[:,-1], pred3)\n",
    "\n",
    "print(score1, score2, score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8375796178343949 0.8407643312101911 0.826963906581741\n"
     ]
    }
   ],
   "source": [
    "xgb1 = XGBClassifier(grow_policy= 'depthwise', \n",
    "                            n_estimators= 500, \n",
    "                            num_parallel_tree= 1, \n",
    "                            tree_method= 'gpu_hist',\n",
    "                            predictor= 'gpu_predictor', \n",
    "                            n_jobs= -1, \n",
    "                            booster= 'dart',\n",
    "                            rate_drop=0.5,\n",
    "                            skip_drop=0.1, \n",
    "                            subsample=0.8)\n",
    "\n",
    "xgb2 = XGBClassifier(grow_policy= 'lossguide', \n",
    "                            n_estimators= 500, \n",
    "                            num_parallel_tree= 1, \n",
    "                            tree_method= 'gpu_hist',\n",
    "                            predictor= 'gpu_predictor', \n",
    "                            n_jobs= -1, \n",
    "                            subsample=0.8)\n",
    "\n",
    "xgb3 = XGBClassifier(grow_policy= 'depthwise', \n",
    "                            n_estimators= 200, \n",
    "                            num_parallel_tree= 3, \n",
    "                            tree_method= 'gpu_hist',\n",
    "                            predictor= 'gpu_predictor', \n",
    "                            n_jobs= -1, \n",
    "                            booster= 'dart',\n",
    "                            rate_drop=0.5,\n",
    "                            skip_drop=0.1, \n",
    "                            subsample=0.8)\n",
    "\n",
    "xgb1.fit(X, y)\n",
    "xgb2.fit(X, y)\n",
    "xgb3.fit(X, y)\n",
    "\n",
    "pred4 = xgb1.predict(df_test.iloc[:,:-1])\n",
    "pred5 = xgb2.predict(df_test.iloc[:,:-1])\n",
    "pred6 = xgb3.predict(df_test.iloc[:,:-1])\n",
    "\n",
    "score4 = accuracy_score(df_test.iloc[:,-1], pred4)\n",
    "score5 = accuracy_score(df_test.iloc[:,-1], pred5)\n",
    "score6 = accuracy_score(df_test.iloc[:,-1], pred6)\n",
    "\n",
    "print(score4, score5, score6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df_train.iloc[:,:-1], df_train.iloc[:,-1]\n",
    "\n",
    "sm = SMOTE(random_state=42)\n",
    "X_res, y_res = sm.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8428874734607219 0.8747346072186837 0.8428874734607219\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "lr = LogisticRegression(n_jobs=-1)\n",
    "xgb = XGBClassifier(n_jobs=-1)\n",
    "\n",
    "rf.fit(X_res, y_res)\n",
    "lr.fit(X_res, y_res)\n",
    "xgb.fit(X_res, y_res)\n",
    "\n",
    "pred1 = rf.predict(df_test.iloc[:,:-1])\n",
    "pred2 = lr.predict(df_test.iloc[:,:-1])\n",
    "pred3 = xgb.predict(df_test.iloc[:,:-1])\n",
    "\n",
    "score1 = accuracy_score(df_test.iloc[:,-1], pred1)\n",
    "score2 = accuracy_score(df_test.iloc[:,-1], pred2)\n",
    "score3 = accuracy_score(df_test.iloc[:,-1], pred3)\n",
    "\n",
    "print(score1, score2, score3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8471337579617835 0.8503184713375797 0.8152866242038217\n"
     ]
    }
   ],
   "source": [
    "xgb1.fit(X_res, y_res)\n",
    "xgb2.fit(X_res, y_res)\n",
    "xgb3.fit(X_res, y_res)\n",
    "\n",
    "pred4 = xgb1.predict(df_test.iloc[:,:-1])\n",
    "pred5 = xgb2.predict(df_test.iloc[:,:-1])\n",
    "pred6 = xgb3.predict(df_test.iloc[:,:-1])\n",
    "\n",
    "score4 = accuracy_score(df_test.iloc[:,-1], pred4)\n",
    "score5 = accuracy_score(df_test.iloc[:,-1], pred5)\n",
    "score6 = accuracy_score(df_test.iloc[:,-1], pred6)\n",
    "\n",
    "print(score4, score5, score6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "      <th>pred5</th>\n",
       "      <th>pred6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2192</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2193</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2194</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2195</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2196 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pred1  pred2  pred3  pred4  pred5  pred6\n",
       "0         0      0      0      0      0      0\n",
       "1         0      0      0      0      0      0\n",
       "2         1      1      1      1      1      1\n",
       "3         1      1      1      1      1      1\n",
       "4         2      2      2      2      2      2\n",
       "...     ...    ...    ...    ...    ...    ...\n",
       "2191      6      6      6      6      6      6\n",
       "2192      2      0      2      2      2      2\n",
       "2193      2      2      2      2      2      1\n",
       "2194      6      6      6      6      6      6\n",
       "2195      5      5      5      5      5      5\n",
       "\n",
       "[2196 rows x 6 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1, model2, model3 = rf, lr, xgb\n",
    "model4, model5, model6 = xgb1, xgb2, xgb3\n",
    "\n",
    "df_train2 = pd.DataFrame()\n",
    "df_train2['pred1'] = model1.predict(X)\n",
    "df_train2['pred2'] = model2.predict(X)\n",
    "df_train2['pred3'] = model3.predict(X)\n",
    "df_train2['pred4'] = model4.predict(X)\n",
    "df_train2['pred5'] = model5.predict(X)\n",
    "df_train2['pred6'] = model6.predict(X)\n",
    "\n",
    "df_train2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred1</th>\n",
       "      <th>pred2</th>\n",
       "      <th>pred3</th>\n",
       "      <th>pred4</th>\n",
       "      <th>pred5</th>\n",
       "      <th>pred6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>942 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     pred1  pred2  pred3  pred4  pred5  pred6\n",
       "0        6      6      6      6      6      6\n",
       "1        6      6      6      6      6      6\n",
       "2        1      1      1      1      1      1\n",
       "3        2      2      2      2      2      2\n",
       "4        2      2      2      2      2      2\n",
       "..     ...    ...    ...    ...    ...    ...\n",
       "937      0      0      0      0      0      0\n",
       "938      6      6      6      6      6      6\n",
       "939      5      2      2      5      5      5\n",
       "940      0      0      5      5      0      2\n",
       "941      0      0      0      0      0      0\n",
       "\n",
       "[942 rows x 6 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test2 = pd.DataFrame()\n",
    "df_test2['pred1'] = model1.predict(df_test.iloc[:,:-1])\n",
    "df_test2['pred2'] = model2.predict(df_test.iloc[:,:-1])\n",
    "df_test2['pred3'] = model3.predict(df_test.iloc[:,:-1])\n",
    "df_test2['pred4'] = model4.predict(df_test.iloc[:,:-1])\n",
    "df_test2['pred5'] = model5.predict(df_test.iloc[:,:-1])\n",
    "df_test2['pred6'] = model6.predict(df_test.iloc[:,:-1])\n",
    "# df_test2['label'] = df_test2_test.iloc[:,-1]\n",
    "\n",
    "df_test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8131634819532909"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model7 = SVC()\n",
    "model7.fit(df_train2, y)\n",
    "pred7 = model7.predict(df_test2)\n",
    "accuracy_score(df_test.iloc[:,-1], pred7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['mean_fit_time',\n",
       " 'mean_score_time',\n",
       " 'mean_test_score',\n",
       " 'param_C',\n",
       " 'param_max_iter',\n",
       " 'params',\n",
       " 'rank_test_score',\n",
       " 'split0_test_score',\n",
       " 'split1_test_score',\n",
       " 'split2_test_score',\n",
       " 'split3_test_score',\n",
       " 'split4_test_score',\n",
       " 'std_fit_time',\n",
       " 'std_score_time',\n",
       " 'std_test_score']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {'max_iter':[100, 1000],\n",
    "          'C':[1,10,100, 10000]}\n",
    "\n",
    "clf = GridSearchCV(lr, param_grid=params)\n",
    "clf.fit(X_res, y_res)\n",
    "sorted(clf.cv_results_.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 100, 'max_iter': 100}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8874734607218684"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=100, n_jobs=-1)\n",
    "model.fit(X_res, y_res)\n",
    "pred = model.predict(df_test.iloc[:,:-1])\n",
    "\n",
    "score = accuracy_score(df_test.iloc[:,-1], pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8895966029723992"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = LogisticRegression(C=10000, n_jobs=-1)\n",
    "model2.fit(X_res, y_res)\n",
    "pred2 = model2.predict(df_test.iloc[:,:-1])\n",
    "\n",
    "score2 = accuracy_score(df_test.iloc[:,-1], pred2)\n",
    "score2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 04. Model Save & Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './models'\n",
    "if not os.path.exists(save_dir) :\n",
    "    os.mkdir(save_dir)\n",
    "    \n",
    "with gzip.open(f'{save_dir}/LR_tfidf.pickle','wb') as f:\n",
    "    pickle.dump(model2, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8895966029723992\n"
     ]
    }
   ],
   "source": [
    "with gzip.open(f'{save_dir}/LR_tfidf.pickle','rb') as f:\n",
    "    model = pickle.load(f)\n",
    "    \n",
    "pred = model.predict(df_test.iloc[:,:-1])\n",
    "score = accuracy_score(df_test.iloc[:,-1], pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STEP 05. Inference & Submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'international': 0,\n",
       " 'economy': 1,\n",
       " 'society': 2,\n",
       " 'sport': 3,\n",
       " 'it': 4,\n",
       " 'politics': 5,\n",
       " 'entertain': 6,\n",
       " 'culture': 7}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'international',\n",
       " 1: 'economy',\n",
       " 2: 'society',\n",
       " 3: 'sport',\n",
       " 4: 'it',\n",
       " 5: 'politics',\n",
       " 6: 'entertain',\n",
       " 7: 'culture'}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_dict2 = {v:k for k, v in labels_dict.items()}\n",
    "labels_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cleanBody</th>\n",
       "      <th>category</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>배진웅 측 \"성폭행 의혹 사실무근…보도 전 B씨 강제추행죄 고소\"[공식]</td>\n",
       "      <td>후배 여배우 성폭행 의혹에 휘말린 배우 배진웅 측이 허위사실 유포에 대한 강경대응 ...</td>\n",
       "      <td>entertain</td>\n",
       "      <td>entertain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>배진웅 측 \"여배우 성추행 고소내용 허위\"(공식)</td>\n",
       "      <td>[조이뉴스24 정명화 기자] 배우 배진웅이 동료여배우 성추행 혐의를 부인했다. 배진...</td>\n",
       "      <td>entertain</td>\n",
       "      <td>entertain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>매일 쏟아지는 코스피 기록들…'동학개미발 가보지 않는 숫자'</td>\n",
       "      <td>11일 서울 영등포구 KB국민은행 여의도지점 스마트딜링룸 전광판에 코스피지수가 전일...</td>\n",
       "      <td>economy</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>정부, 코로나19 의료진 처우 지적에 \"인력충원 등 개선 지속 논의\"</td>\n",
       "      <td>정부가 12일 신종 코로나바이러스 감염증(코로나19) 확산에 따른 의료현장 인력 부...</td>\n",
       "      <td>society</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>집합금지 완화 토요일 발표 전망…중수본 \"엄격한 방역 조건으로 해제 검토\"</td>\n",
       "      <td>정부가 11일부터 코로나19로 피해를 입은 소상공인과 고용 취약계층에 버팀목자금, ...</td>\n",
       "      <td>society</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>日코로나 신규확진 600명…\"인슐린주사기로 백신1병에 7회\"</td>\n",
       "      <td>일본 수도권 일부 지역에 신종 코로나바이러스 감염증(코로나19) 긴급사태가 발령 중...</td>\n",
       "      <td>society</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>[슬라이드 뉴스] 이지은 누구? '금홍아 금홍아'로 신인상 휩쓴 '청춘스타'</td>\n",
       "      <td>숨진 채 발견된 배우 이지은에 대해 관심이 쏠리고 있다. 1971년생인 이지은은 1...</td>\n",
       "      <td>entertain</td>\n",
       "      <td>entertain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>文 “검찰 공정성 신뢰 나아지지 않아… 기소·수사권 분리, 나아가야 할 방향”</td>\n",
       "      <td>문재인 캐리커처 문재인(얼굴) 대통령은 8일 \"기소권과 수사권 분리는 앞으로도 꾸준...</td>\n",
       "      <td>politics</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>中, '백신여권' 도입에 \"편리한 인원왕래 요구 절실\"</td>\n",
       "      <td>[서울=뉴시스] 중국 외교부가 '중국판 백신 여권'에 대해 추가적인 설명을 내놓았다...</td>\n",
       "      <td>international</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>獨 여당 의원, 중국산 마스크 중개수수료 꿀꺽…메르켈에 부담 [인더머니]</td>\n",
       "      <td>[AP] 앙겔라 메르켈 독일 총리가 소속된 기독민주당(CDU)·기독사회당(CSU) ...</td>\n",
       "      <td>international</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>942 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0       배진웅 측 \"성폭행 의혹 사실무근…보도 전 B씨 강제추행죄 고소\"[공식]   \n",
       "1                    배진웅 측 \"여배우 성추행 고소내용 허위\"(공식)   \n",
       "2              매일 쏟아지는 코스피 기록들…'동학개미발 가보지 않는 숫자'   \n",
       "3         정부, 코로나19 의료진 처우 지적에 \"인력충원 등 개선 지속 논의\"   \n",
       "4      집합금지 완화 토요일 발표 전망…중수본 \"엄격한 방역 조건으로 해제 검토\"   \n",
       "..                                           ...   \n",
       "937            日코로나 신규확진 600명…\"인슐린주사기로 백신1병에 7회\"   \n",
       "938   [슬라이드 뉴스] 이지은 누구? '금홍아 금홍아'로 신인상 휩쓴 '청춘스타'   \n",
       "939  文 “검찰 공정성 신뢰 나아지지 않아… 기소·수사권 분리, 나아가야 할 방향”   \n",
       "940               中, '백신여권' 도입에 \"편리한 인원왕래 요구 절실\"   \n",
       "941     獨 여당 의원, 중국산 마스크 중개수수료 꿀꺽…메르켈에 부담 [인더머니]   \n",
       "\n",
       "                                             cleanBody       category  \\\n",
       "0    후배 여배우 성폭행 의혹에 휘말린 배우 배진웅 측이 허위사실 유포에 대한 강경대응 ...      entertain   \n",
       "1    [조이뉴스24 정명화 기자] 배우 배진웅이 동료여배우 성추행 혐의를 부인했다. 배진...      entertain   \n",
       "2    11일 서울 영등포구 KB국민은행 여의도지점 스마트딜링룸 전광판에 코스피지수가 전일...        economy   \n",
       "3    정부가 12일 신종 코로나바이러스 감염증(코로나19) 확산에 따른 의료현장 인력 부...        society   \n",
       "4    정부가 11일부터 코로나19로 피해를 입은 소상공인과 고용 취약계층에 버팀목자금, ...        society   \n",
       "..                                                 ...            ...   \n",
       "937  일본 수도권 일부 지역에 신종 코로나바이러스 감염증(코로나19) 긴급사태가 발령 중...        society   \n",
       "938  숨진 채 발견된 배우 이지은에 대해 관심이 쏠리고 있다. 1971년생인 이지은은 1...      entertain   \n",
       "939  문재인 캐리커처 문재인(얼굴) 대통령은 8일 \"기소권과 수사권 분리는 앞으로도 꾸준...       politics   \n",
       "940  [서울=뉴시스] 중국 외교부가 '중국판 백신 여권'에 대해 추가적인 설명을 내놓았다...  international   \n",
       "941  [AP] 앙겔라 메르켈 독일 총리가 소속된 기독민주당(CDU)·기독사회당(CSU) ...  international   \n",
       "\n",
       "            result  \n",
       "0        entertain  \n",
       "1        entertain  \n",
       "2          economy  \n",
       "3          society  \n",
       "4          society  \n",
       "..             ...  \n",
       "937  international  \n",
       "938      entertain  \n",
       "939        society  \n",
       "940  international  \n",
       "941  international  \n",
       "\n",
       "[942 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['result'] = pred\n",
    "test['result'] = test['result'].map(lambda x : labels_dict2[x])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>cleanBody</th>\n",
       "      <th>category</th>\n",
       "      <th>result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>배진웅 측 \"성폭행 의혹 사실무근…보도 전 B씨 강제추행죄 고소\"[공식]</td>\n",
       "      <td>후배 여배우 성폭행 의혹에 휘말린 배우 배진웅 측이 허위사실 유포에 대한 강경대응 ...</td>\n",
       "      <td>entertain</td>\n",
       "      <td>entertain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>배진웅 측 \"여배우 성추행 고소내용 허위\"(공식)</td>\n",
       "      <td>[조이뉴스24 정명화 기자] 배우 배진웅이 동료여배우 성추행 혐의를 부인했다. 배진...</td>\n",
       "      <td>entertain</td>\n",
       "      <td>entertain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>매일 쏟아지는 코스피 기록들…'동학개미발 가보지 않는 숫자'</td>\n",
       "      <td>11일 서울 영등포구 KB국민은행 여의도지점 스마트딜링룸 전광판에 코스피지수가 전일...</td>\n",
       "      <td>economy</td>\n",
       "      <td>economy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>정부, 코로나19 의료진 처우 지적에 \"인력충원 등 개선 지속 논의\"</td>\n",
       "      <td>정부가 12일 신종 코로나바이러스 감염증(코로나19) 확산에 따른 의료현장 인력 부...</td>\n",
       "      <td>society</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>집합금지 완화 토요일 발표 전망…중수본 \"엄격한 방역 조건으로 해제 검토\"</td>\n",
       "      <td>정부가 11일부터 코로나19로 피해를 입은 소상공인과 고용 취약계층에 버팀목자금, ...</td>\n",
       "      <td>society</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>日코로나 신규확진 600명…\"인슐린주사기로 백신1병에 7회\"</td>\n",
       "      <td>일본 수도권 일부 지역에 신종 코로나바이러스 감염증(코로나19) 긴급사태가 발령 중...</td>\n",
       "      <td>society</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>[슬라이드 뉴스] 이지은 누구? '금홍아 금홍아'로 신인상 휩쓴 '청춘스타'</td>\n",
       "      <td>숨진 채 발견된 배우 이지은에 대해 관심이 쏠리고 있다. 1971년생인 이지은은 1...</td>\n",
       "      <td>entertain</td>\n",
       "      <td>entertain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>939</th>\n",
       "      <td>文 “검찰 공정성 신뢰 나아지지 않아… 기소·수사권 분리, 나아가야 할 방향”</td>\n",
       "      <td>문재인 캐리커처 문재인(얼굴) 대통령은 8일 \"기소권과 수사권 분리는 앞으로도 꾸준...</td>\n",
       "      <td>politics</td>\n",
       "      <td>society</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>940</th>\n",
       "      <td>中, '백신여권' 도입에 \"편리한 인원왕래 요구 절실\"</td>\n",
       "      <td>[서울=뉴시스] 중국 외교부가 '중국판 백신 여권'에 대해 추가적인 설명을 내놓았다...</td>\n",
       "      <td>international</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>941</th>\n",
       "      <td>獨 여당 의원, 중국산 마스크 중개수수료 꿀꺽…메르켈에 부담 [인더머니]</td>\n",
       "      <td>[AP] 앙겔라 메르켈 독일 총리가 소속된 기독민주당(CDU)·기독사회당(CSU) ...</td>\n",
       "      <td>international</td>\n",
       "      <td>international</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>942 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title  \\\n",
       "0       배진웅 측 \"성폭행 의혹 사실무근…보도 전 B씨 강제추행죄 고소\"[공식]   \n",
       "1                    배진웅 측 \"여배우 성추행 고소내용 허위\"(공식)   \n",
       "2              매일 쏟아지는 코스피 기록들…'동학개미발 가보지 않는 숫자'   \n",
       "3         정부, 코로나19 의료진 처우 지적에 \"인력충원 등 개선 지속 논의\"   \n",
       "4      집합금지 완화 토요일 발표 전망…중수본 \"엄격한 방역 조건으로 해제 검토\"   \n",
       "..                                           ...   \n",
       "937            日코로나 신규확진 600명…\"인슐린주사기로 백신1병에 7회\"   \n",
       "938   [슬라이드 뉴스] 이지은 누구? '금홍아 금홍아'로 신인상 휩쓴 '청춘스타'   \n",
       "939  文 “검찰 공정성 신뢰 나아지지 않아… 기소·수사권 분리, 나아가야 할 방향”   \n",
       "940               中, '백신여권' 도입에 \"편리한 인원왕래 요구 절실\"   \n",
       "941     獨 여당 의원, 중국산 마스크 중개수수료 꿀꺽…메르켈에 부담 [인더머니]   \n",
       "\n",
       "                                             cleanBody       category  \\\n",
       "0    후배 여배우 성폭행 의혹에 휘말린 배우 배진웅 측이 허위사실 유포에 대한 강경대응 ...      entertain   \n",
       "1    [조이뉴스24 정명화 기자] 배우 배진웅이 동료여배우 성추행 혐의를 부인했다. 배진...      entertain   \n",
       "2    11일 서울 영등포구 KB국민은행 여의도지점 스마트딜링룸 전광판에 코스피지수가 전일...        economy   \n",
       "3    정부가 12일 신종 코로나바이러스 감염증(코로나19) 확산에 따른 의료현장 인력 부...        society   \n",
       "4    정부가 11일부터 코로나19로 피해를 입은 소상공인과 고용 취약계층에 버팀목자금, ...        society   \n",
       "..                                                 ...            ...   \n",
       "937  일본 수도권 일부 지역에 신종 코로나바이러스 감염증(코로나19) 긴급사태가 발령 중...        society   \n",
       "938  숨진 채 발견된 배우 이지은에 대해 관심이 쏠리고 있다. 1971년생인 이지은은 1...      entertain   \n",
       "939  문재인 캐리커처 문재인(얼굴) 대통령은 8일 \"기소권과 수사권 분리는 앞으로도 꾸준...       politics   \n",
       "940  [서울=뉴시스] 중국 외교부가 '중국판 백신 여권'에 대해 추가적인 설명을 내놓았다...  international   \n",
       "941  [AP] 앙겔라 메르켈 독일 총리가 소속된 기독민주당(CDU)·기독사회당(CSU) ...  international   \n",
       "\n",
       "            result  \n",
       "0        entertain  \n",
       "1        entertain  \n",
       "2          economy  \n",
       "3          society  \n",
       "4          society  \n",
       "..             ...  \n",
       "937  international  \n",
       "938      entertain  \n",
       "939        society  \n",
       "940  international  \n",
       "941  international  \n",
       "\n",
       "[942 rows x 4 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.to_csv('submission.csv', index=False, encoding='utf-8-sig')\n",
    "df = pd.read_csv('submission.csv')\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
