{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 01. Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 02. Set Crawling File List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['ddanzzi', 'clien', 'bobe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1  = pd.read_csv(\"naver.csv\")\n",
    "df2 = pd.read_csv(\"youtube.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 03. Delete Spamming or Repititive Results - option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For user analysis, sometimes spamming and repetitve crawling results are what you need.\n",
    "# So when you need those results, you can skip this STEP or do it in part.\n",
    "\n",
    "for name in tqdm(list) :\n",
    "    name_01 = name + \".csv\"    \n",
    "    df = pd.read_csv(name_01).dropna()\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "       \n",
    "    print(\"삭제 대상을 확인 중입니다.\")\n",
    "    \n",
    "    for i in tqdm(range(len(df))) :\n",
    "        try :\n",
    "            target_01 = len( [ x for x in df['title'] if x == df['title'][i] ])\n",
    "        except :\n",
    "            target_01 = len( [ x for x in df['user_text'] if x == df['user_text'][i] ])\n",
    "            \n",
    "        target_02 = len( [ y for y in df['url'] if y == df['url'][i] ])\n",
    "        \n",
    "        if target_01 > 1 :\n",
    "            df['title'][i] = \"delete target\"\n",
    "        elif target_02 > 1 :\n",
    "            df['url'][i] = \"delete target\"\n",
    "    \n",
    "    target_list = []\n",
    "    \n",
    "    print(\"삭제 대상을 제거합니다.\")\n",
    "    \n",
    "    before = len(df)\n",
    "    \n",
    "    for j in range(len(df)) :\n",
    "        if df['title'][j] == \"delete target\" or df['url'][j] == \"delete target\" :\n",
    "            target_list.append(j)\n",
    "            \n",
    "    df.drop(df.index[target_list], inplace=True)\n",
    "    \n",
    "    after = len(df)\n",
    "    \n",
    "    print(f\"file name {name} 작업 완료...\")\n",
    "    print(f\"총 {before - after}개의 열이 삭제되었습니다.\")\n",
    "    \n",
    "    if os.path.isdir(\"./preprocessing\") :\n",
    "        pass\n",
    "    else :\n",
    "        os.mkdir(\"./preprocessing\")\n",
    "    \n",
    "    df.to_csv(f\"./preprocessing/{name_01}\", index=False)\n",
    "    print(f\"파일 저장 완료...저장 위치 : ./preprocessing/{name_01}\")\n",
    "    \n",
    "\n",
    "print(\"preprocessing 작업을 완료하였습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STEP 04. Create Derivative Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list = ['./preprocessing/ddanzzi', './preprocessing/clien', './preprocessing/bobe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"fm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"{name}.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.reset_index(drop=True)\n",
    "for i in range(len(df1)) :\n",
    "    if pd.isna(df1['user_text'][i]) :\n",
    "        df1['user_text'][i] = df1['title'][i]\n",
    "\n",
    "df1['keyword'] = \"없음\"\n",
    "df2 = df1\n",
    "\n",
    "for i in range(len(df2)) :      \n",
    "        try :\n",
    "\n",
    "            if \"재명\" in df2['title'][i] :\n",
    "                df2['keyword'][i] = \"이재명\"\n",
    "                print(\"이재명 :\", df2['title'][i], df2['keyword'][i])\n",
    "        except :\n",
    "            print(i,  df2['title'][i])\n",
    "df3 = df2.reset_index(drop=True)\n",
    "df2 = df1\n",
    "\n",
    "for j in range(len(df2)) : \n",
    "    \n",
    "        if \"낙연\" in df2['title'][j] :\n",
    "            df2['keyword'][j] = \"이낙연\"\n",
    "            print(\"이낙연 :\", df2['title'][j], df2['keyword'][j])\n",
    "            \n",
    "df3 = df3.append(df2).reset_index(drop=True)\n",
    "df2 = df1\n",
    "\n",
    "for k in range(len(df2)) : \n",
    "    \n",
    "        if \"세균\" in df2['title'][k] or \"정세균\" in df2['title'][k] :\n",
    "            df2['keyword'][k] = \"정세균\"\n",
    "            print(\"정세균 :\", df2['title'][k], df2['keyword'][k])\n",
    "\n",
    "df3 = df3.append(df2).reset_index(drop=True)\n",
    "df3 = df3.drop_duplicates()\n",
    "df3.sort_values('date')\n",
    "df3.reset_index(drop=True, inplace=True)\n",
    "df3.to_csv(f\"{name}2.csv\",index=False, encoding='utf-8-sig')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.reset_index(drop=True)\n",
    "for i in range(len(df1)) :\n",
    "    if pd.isna(df1['user_text'][i]) :\n",
    "        df1['user_text'][i] = df1['title'][i]\n",
    "\n",
    "df1['keyword'] = \"없음\"\n",
    "df2 = df1\n",
    "\n",
    "for i in range(len(df2)) :      \n",
    "        try :\n",
    "\n",
    "            if \"재명\" in df2['title'][i] :\n",
    "                df2['keyword'][i] = \"이재명\"\n",
    "                print(\"이재명 :\", df2['title'][i], df2['keyword'][i])\n",
    "        except :\n",
    "            print(i,  df2['title'][i])\n",
    "df3 = df2.dropna().reset_index(drop=True)\n",
    "df2 = df1\n",
    "\n",
    "for j in range(len(df2)) : \n",
    "    \n",
    "        if \"낙연\" in df2['title'][j] :\n",
    "            df2['keyword'][j] = \"이낙연\"\n",
    "            print(\"이낙연 :\", df2['title'][j], df2['keyword'][j])\n",
    "            \n",
    "df3 = df3.append(df2).dropna().reset_index(drop=True)\n",
    "df2 = df1\n",
    "\n",
    "for k in range(len(df2)) : \n",
    "    \n",
    "        if \"세균\" in df2['title'][k] or \"정세균\" in df2['title'][k] :\n",
    "            df2['keyword'][k] = \"정세균\"\n",
    "            print(\"정세균 :\", df2['title'][k], df2['keyword'][k])\n",
    "\n",
    "df3 = df3.append(df2).dropna().reset_index(drop=True)\n",
    "df3 = df3.drop_duplicates()\n",
    "df3.sort_values('date')\n",
    "df3.reset_index(drop=True, inplace=True)\n",
    "df3.to_csv(f\"{name}2.csv\",index=False, encoding='utf-8-sig')\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df3)) :\n",
    "    if pd.isna(df3['date'][i]) :\n",
    "        df3['date'][i] = df3['time'][i]\n",
    "df4 = df3.dropna(axis=1)\n",
    "df4.to_csv(f\"{name}2.csv\",index=False, encoding='utf-8-sig')\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df3[df3['keyword']==\"이낙연\"]),len(df3[df3['keyword']==\"이재명\"]),len(df3[df3['keyword']==\"정세균\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['keyword'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_list = []\n",
    "for i in range(len(df)) :\n",
    "    if pd.isna(df['user_text'][i]) :\n",
    "        df['user_text'][i] = \"\"\n",
    "    if (\"사면\" in df['title'][i] or \"사면\" in df['user_text'][i]) and (\"낙연\" in df['title'][i] or \"낙연\" in df['user_text'][i]) :\n",
    "        index_list.append(i)\n",
    "print(len(index_list), index_list)\n",
    "\n",
    "df1 = df.loc[index_list]\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv(\"bbombbu_pre.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1.append(df2).sort_values(['date', 'domain', 'keyword'])\n",
    "df3.reset_index(drop=True, inplace=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv(\"news.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"clien.csv\").dropna()\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['keyword'] = \"없음\"\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.drop_duplicates()\n",
    "df4.reset_index(drop=True, inplace=True)\n",
    "df4.to_csv(\"clien.csv\")\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 유튜브\n",
    "\n",
    "# 게시물 크롤링 후 댓글 파일 만들기\n",
    "# 이와 같은 파생 결과물은 크롤링한 도메인이나 분석 목적 등에 따라 달라질 수 있으므로 유동으로 코딩\n",
    "\n",
    "df1 = pd.read_csv(\"youtube.csv\")\n",
    "\n",
    "# comment_keyword = []\n",
    "comment_date = []\n",
    "comment_text = []\n",
    "\n",
    "for i in range(len(df1)) :\n",
    "    comments = df1['comment'][i].replace(\"'\",\"\").replace('\"','').replace(\" \",\"\")[1:-1].split(\",\")\n",
    "    for comment in comments :\n",
    "        comment_date.append(df1['date'][i])\n",
    "        comment_text.append(comment.split('::')[-1].strip())\n",
    "        \n",
    "new_df = pd.DataFrame()\n",
    "# new_df['keyword'] = \"\"\n",
    "new_df['date'] = pd.Series(comment_date) \n",
    "new_df['user_text'] = pd.Series(comment_text)\n",
    "\n",
    "# new_df['keyword'] = \"4주년연설\"\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.sort_values(by=['date'], inplace=True)\n",
    "new_df.reset_index(drop=True, inplace=True)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('youtube_com.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# 유튜브\n",
    "\n",
    "# 게시물 크롤링 후 댓글 파일 만들기\n",
    "# 이와 같은 파생 결과물은 크롤링한 도메인이나 분석 목적 등에 따라 달라질 수 있으므로 유동으로 코딩\n",
    "\n",
    "# df1 = pd.read_csv(\"community_clien.csv\")\n",
    "\n",
    "\n",
    "comment_keyword = []\n",
    "comment_name = []\n",
    "comment_date = []\n",
    "comment_text = []\n",
    "\n",
    "\n",
    "for i in range(len(df1)) :\n",
    "#     print(i, df1['comment'][i])\n",
    "    comments = df1['comment'][i].split(\"',\")[1:-1]\n",
    "    \n",
    "    try :          \n",
    "\n",
    "        for comment in comments :\n",
    "\n",
    "            print(len(comment.strip()))\n",
    "            if len(comment.strip()) > 3 :\n",
    "                print(\"원문 :\", comment.strip())\n",
    "                \n",
    "                name = comment.replace(\"작성자 :\",\"\").split(\" :: \")[0].strip().split(\" \")[0].replace(\"'\",\"\").replace('\"','')\n",
    "                \n",
    "\n",
    "                date = df1['time'][i]\n",
    "                    \n",
    "                check_point_01 = comment.replace(\"작성자 :\",\"\").split(\" :: \")[1:]\n",
    "        \n",
    "                text = check_point_01\n",
    "\n",
    "                if len(text) > 1 :\n",
    "\n",
    "                    check_point_01 = comment.split(\", \")[0].split(\" : \")[1:]\n",
    "\n",
    "                    print(\"파생 원문 :\", comment.split(\", \")[1])\n",
    "                    comment2 = comment.split(\", \")[1]\n",
    "                    name2 = comment2.replace(\"작성자 :\",\"\").split(\" :: \")[0].strip().split(\" \")[0].replace(\"'\",\"\").replace('\"','')\n",
    "\n",
    "                    if len(comment2.replace(\"작성자 :\",\"\").split(\" :: \")[0].strip().split(\" \")) == 2 :\n",
    "                        for j in comment2.replace(\"작성자 :\",\"\").split(\" :: \")[0].strip().split(\" \")[-1:] :\n",
    "                            date2 = date2 + j + \" \"\n",
    "                        date2 = date2.strip()\n",
    "\n",
    "                    else :\n",
    "\n",
    "                        for j in comment2.replace(\"작성자 :\",\"\").split(\" :: \")[0].strip().split(\" \")[-2:] :\n",
    "                            date2 = date2 + j + \" \"\n",
    "                        date2 = date2.strip()\n",
    "        #             date = comment.split(\" : \")[0].strip().split(\" \")[-2:]\n",
    "\n",
    "                    text2 = \"\"\n",
    "                    for k in comment2.replace(\"작성자 :\",\"\").split(\" :: \")[1:] :\n",
    "                        text2 = text2 + k + \" \"\n",
    "                    \n",
    "                    try : \n",
    "                        text2 = text2.strip().split(\" ] \")[1]\n",
    "                    except :\n",
    "                        text2 = text2.strip()\n",
    "                    \n",
    "\n",
    "                    print(\"name :\", name2.replace(\"본문\",\"\"))\n",
    "                    print(\"date :\", date2)\n",
    "                    print(\"text :\", text2)\n",
    "                    print(\"\\n\")\n",
    "                    \n",
    "                    keyword = df1['keyword'][i]\n",
    "                    \n",
    "                    comment_keyword.append(keyword)\n",
    "                    comment_name.append(name2.replace(\"본문\",\"\"))\n",
    "                    comment_date.append(date2)\n",
    "                    comment_text.append(text2)\n",
    "\n",
    "                    text = \"\"\n",
    "                    for k in check_point_01 :\n",
    "                        text = text + k + \" \"\n",
    "                    text = text.strip()   \n",
    "                else :\n",
    "                    text = \"\"\n",
    "                    for k in check_point_01 :\n",
    "                        text = text + k\n",
    "\n",
    "                    try : \n",
    "                        text = text.strip().split(\" ] \")[1]\n",
    "                    except :\n",
    "                        text = text.strip()\n",
    "                        \n",
    "                print(\"name :\", name.replace(\"본문\",\"\"))\n",
    "                print(\"date :\", date)\n",
    "                print(\"text :\", text)\n",
    "                print(\"\\n\")\n",
    "                \n",
    "#                 keyword = df1['keyword'][i]\n",
    "\n",
    "                comment_keyword.append(keyword)\n",
    "                comment_name.append(name.replace(\"본문\",\"\"))\n",
    "                comment_date.append(date)\n",
    "                comment_text.append(text)\n",
    "                \n",
    "    except :\n",
    "        pass\n",
    "            \n",
    "new_df = pd.DataFrame()\n",
    "new_df['keyword'] = pd.Series(comment_keyword)\n",
    "new_df['user_name'] = pd.Series(comment_name)\n",
    "new_df['date'] = pd.Series(comment_date) \n",
    "new_df['user_text'] = pd.Series(comment_text)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df4[df4['keyword'] == \"4주년연설\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['com_text'][0][1:-1].split(\", '\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(f\"{name}2.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 딴지 임시\n",
    "\n",
    "# df4 = df1\n",
    "\n",
    "user_name = []\n",
    "date = []\n",
    "user_text = []\n",
    "keywords = []\n",
    "\n",
    "for i in range(len(df4)) :\n",
    "    comments = df4['com_text'][i][1:-1].split(\"', '\")\n",
    "#     print(comments)\n",
    "    for comment in comments :\n",
    "        \n",
    "        try :            \n",
    "\n",
    "            target = comment.split(' :: ')\n",
    "            \n",
    "            if len(target) < 2 :\n",
    "                raise Exception(\"파생구문 확인\")\n",
    "                break\n",
    "            \n",
    "            print(\"원문 :\", target)\n",
    "            print(\"user_name :\", target[0].replace(\"작성자 : \",\"\"))\n",
    "            print(\"date :\", df4['date'][i])\n",
    "            print(\"user_text :\", target[1])\n",
    "            print(\"\\n\")\n",
    "            \n",
    "            keywords.append(df4['keyword'][i])\n",
    "            user_name.append(target[0].replace(\"작성자 : \",\"\"))\n",
    "            date.append(df4['date'][i])\n",
    "            user_text.append(target[1])\n",
    "            \n",
    "        except :\n",
    "            \n",
    "            try :\n",
    "                target = comment.split(' : ')\n",
    "\n",
    "                if len(target) < 2 :\n",
    "                    print(\"기준 미적합 :\", target, \"\\n\")\n",
    "                    break\n",
    "\n",
    "                print(\"원문 :\", target)\n",
    "                print(\"user_name :\", target[0].split(' 2021')[0].replace(\"작성자 : \",\"\"))\n",
    "                print(\"date :\", df4['date'][i])\n",
    "                print(\"user_text :\", target[1])\n",
    "                print(\"\\n\")\n",
    "                \n",
    "                keywords.append(df4['keyword'][i])\n",
    "                user_name.append(target[0].split(' 2021')[0].replace(\"작성자 : \",\"\"))\n",
    "                date.append(df4['date'][i])\n",
    "                user_text.append(target[1])\n",
    "            except :\n",
    "                \n",
    "                pass\n",
    "    \n",
    "    \n",
    "new_df = pd.DataFrame()\n",
    "new_df['keyword'] = pd.Series(keywords)\n",
    "new_df['user_name'] = pd.Series(user_name)\n",
    "new_df['date'] = pd.Series(date) \n",
    "new_df['user_text'] = pd.Series(user_text)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df00 = new_df.append(df1).dropna(axis=1)\n",
    "df00.reset_index(drop=True, inplace=True)\n",
    "df00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df00.to_csv(\"fm_com.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 딴지, 클리앙\n",
    "\n",
    "df4 = df1\n",
    "\n",
    "keyword = []\n",
    "user_name = []\n",
    "date = []\n",
    "user_text = []\n",
    "\n",
    "for i in range(len(df4)) :\n",
    "    comments = df4['com_text'][i][1:-1].split(\"', '\")\n",
    "#     print(comments)\n",
    "    for comment in comments :\n",
    "        \n",
    "        try :            \n",
    "\n",
    "            target = comment.split(' :: ')\n",
    "            \n",
    "            if len(target) < 2 :\n",
    "                raise Exception(\"파생구문 확인\")\n",
    "                break\n",
    "            \n",
    "            print(\"원문 :\", target)\n",
    "            print(\"keyword :\", df4['keyword'][i])\n",
    "            print(\"user_name :\", target[0].replace(\"작성자 : \",\"\"))\n",
    "            print(\"date :\", df4['date'][i])\n",
    "            print(\"user_text :\", target[1])\n",
    "            print(\"\\n\")\n",
    "\n",
    "            keyword.append(df4['keyword'][i])\n",
    "            user_name.append(target[0].replace(\"작성자 : \",\"\"))\n",
    "            date.append(df4['date'][i])\n",
    "            user_text.append(target[1])\n",
    "            \n",
    "        except :\n",
    "            \n",
    "            try :\n",
    "                target = comment.split(' : ')\n",
    "\n",
    "                if len(target) < 2 :\n",
    "                    print(\"기준 미적합 :\", target, \"\\n\")\n",
    "                    break\n",
    "\n",
    "                print(\"원문 :\", target)\n",
    "                print(\"keyword :\", df4['keyword'][i])\n",
    "                print(\"user_name :\", target[0].split(' 2021')[0].replace(\"작성자 : \",\"\"))\n",
    "                print(\"date :\", df4['date'][i])\n",
    "                print(\"user_text :\", target[1])\n",
    "                print(\"\\n\")\n",
    "\n",
    "                keyword.append(df4['keyword'][i])\n",
    "                user_name.append(target[0].split(' 2021')[0].replace(\"작성자 : \",\"\"))\n",
    "                date.append(df4['date'][i])\n",
    "                user_text.append(target[1])\n",
    "            except :\n",
    "                \n",
    "                pass\n",
    "    \n",
    "    \n",
    "new_df = pd.DataFrame()\n",
    "new_df['keyword'] = pd.Series(keyword)\n",
    "new_df['user_name'] = pd.Series(user_name)\n",
    "new_df['date'] = pd.Series(date) \n",
    "new_df['user_text'] = pd.Series(user_text)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.sort_values(by='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = new_df.append(df4).dropna(axis=1).sort_values(by='date')\n",
    "df.drop_duplicates()\n",
    "# df = df[2:]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "# df.to_csv(\"ddanzi_com.csv\", index=False, encoding='utf-8-sig')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"{name}_com.csv\", index=False, encoding='utf-8-sig')\n",
    "print(f\"{name}_com.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 딴지\n",
    "\n",
    "# 게시물 크롤링 후 댓글 파일 만들기\n",
    "# 이와 같은 파생 결과물은 크롤링한 도메인이나 분석 목적 등에 따라 달라질 수 있으므로 유동으로 코딩\n",
    "\n",
    "df1 = pd.read_csv(\"ddanzi.csv\")\n",
    "# df1 = df4\n",
    "\n",
    "# comment_keyword = []\n",
    "comment_name = []\n",
    "comment_date = []\n",
    "comment_text = []\n",
    "\n",
    "\n",
    "for i in range(len(df1)) :\n",
    "    print(i, df1['com_text'][i])\n",
    "    comments = df1['com_text'][i][1:-1].split(\"',\")\n",
    "    \n",
    "    try :          \n",
    "\n",
    "        for comment in comments :\n",
    "\n",
    "            print(len(comment.strip()))\n",
    "            if len(comment.strip()) > 3 :\n",
    "                print(\"원문 :\", comment.strip())\n",
    "                \n",
    "                name = comment.replace(\"작성자 : \",\"\").split(\" :: \")[0].strip().split(\" \")[0].replace(\"'\",\"\").replace('\"','')\n",
    "                \n",
    "\n",
    "                date = \"\"\n",
    "                \n",
    "                if len(comment.replace(\"작성자 : \",\"\").split(\" :: \")[0].strip().split(\" \")) == 2 :\n",
    "                    for j in comment.replace(\"작성자 : \",\"\").split(\" :: \")[0].strip().split(\" \")[-1:] :\n",
    "                        date = date + j + \" \"\n",
    "                    date = date.strip()\n",
    "                    \n",
    "                else :\n",
    "                    \n",
    "                    for j in comment.replace(\"작성자 : \",\"\").split(\" :: \")[0].strip().split(\" \")[-2:] :\n",
    "                        date = date + j + \" \"\n",
    "                    date = date.strip()\n",
    "    #             date = comment.split(\" : \")[0].strip().split(\" \")[-2:]\n",
    "                check_point_01 = comment.replace(\"작성자 : \",\"\").split(\" :: \")[1:]\n",
    "        \n",
    "                text = check_point_01\n",
    "\n",
    "                if len(text) > 1 :\n",
    "\n",
    "                    check_point_01 = comment.split(\"', \")[0].split(\" : \")[1:]\n",
    "\n",
    "                    print(\"파생 원문 :\", comment.split(\", \")[1])\n",
    "                    comment2 = comment.split(\", \")[1]\n",
    "                    name2 = comment2.replace(\"작성자 : \",\"\").split(\" :: \")[0].strip().split(\" \")[0].replace(\"'\",\"\").replace('\"','')\n",
    "\n",
    "                    if len(comment2.replace(\"작성자 : \",\"\").split(\" :: \")[0].strip().split(\" \")) == 2 :\n",
    "                        for j in comment2.replace(\"작성자 : \",\"\").split(\" :: \")[0].strip().split(\" \")[-1:] :\n",
    "                            date2 = date2 + j + \" \"\n",
    "                        date2 = date2.strip()\n",
    "\n",
    "                    else :\n",
    "\n",
    "                        for j in comment2.replace(\"작성자 : \",\"\").split(\" :: \")[0].strip().split(\" \")[-2:] :\n",
    "                            date2 = date2 + j + \" \"\n",
    "                        date2 = date2.strip()\n",
    "        #             date = comment.split(\" : \")[0].strip().split(\" \")[-2:]\n",
    "\n",
    "                    text2 = \"\"\n",
    "                    for k in comment2.replace(\"작성자 : \",\"\").split(\" :: \")[1:] :\n",
    "                        text2 = text2 + k + \" \"\n",
    "                    \n",
    "                    try : \n",
    "                        text2 = text2.strip().split(\" ] \")[1]\n",
    "                    except :\n",
    "                        text2 = text2.strip()\n",
    "                    \n",
    "\n",
    "                    print(\"name :\", name2.replace(\"본문\",\"\"))\n",
    "                    print(\"date :\", date2)\n",
    "                    print(\"text :\", text2)\n",
    "                    print(\"\\n\")\n",
    "                    \n",
    "                    keyword = df1['keyword'][i]\n",
    "                    \n",
    "                    comment_keyword.append(keyword)\n",
    "                    comment_name.append(name2.replace(\"본문\",\"\"))\n",
    "                    comment_date.append(date2)\n",
    "                    comment_text.append(text2)\n",
    "\n",
    "                    text = \"\"\n",
    "                    for k in check_point_01 :\n",
    "                        text = text + k + \" \"\n",
    "                    text = text.strip()   \n",
    "                else :\n",
    "                    text = \"\"\n",
    "                    for k in check_point_01 :\n",
    "                        text = text + k\n",
    "\n",
    "                    try : \n",
    "                        text = text.strip().split(\" ] \")[1]\n",
    "                    except :\n",
    "                        text = text.strip()\n",
    "                        \n",
    "                print(\"name :\", name.replace(\"본문\",\"\"))\n",
    "                print(\"date :\", date)\n",
    "                print(\"text :\", text)\n",
    "                print(\"\\n\")\n",
    "                \n",
    "                keyword = df1['keyword'][i]\n",
    "\n",
    "                comment_keyword.append(keyword)\n",
    "                comment_name.append(name.replace(\"본문\",\"\"))\n",
    "                comment_date.append(date)\n",
    "                comment_text.append(text)\n",
    "                \n",
    "    except :\n",
    "        pass\n",
    "            \n",
    "new_df = pd.DataFrame()\n",
    "new_df['keyword'] = pd.Series(comment_keyword)\n",
    "new_df['user_name'] = pd.Series(comment_name)\n",
    "new_df['date'] = pd.Series(comment_date) \n",
    "new_df['user_text'] = pd.Series(comment_text)\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.dropna(inplace=True)\n",
    "new_df.sort_values(by='date', inplace=True)\n",
    "new_df.reset_index(drop=True, inplace=True)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['keyword', 'com_cnt', 'com_text', 'user_text', 'domain', 'like_cnt', 'date', 'title', 'url', 'view_cnt', 'user_name']\n",
    "df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df33 = pd.concat([df.dropna(), new_df]).dropna(axis=1).sort_values('keyword').reset_index(drop=True)\n",
    "df33.to_csv(\"keyword_clien.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df22 = pd.concat([df.dropna(),new_df]).dropna(axis=1).sort_values('keyword').reset_index(drop=True)\n",
    "df22.to_csv(\"keyword_bobe.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len([x for x in new_df['keyword'] if x == \"이재명\" or x== \"이낙연\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"./keyword_bobe_comments.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"community_ddanzi.csv\")\n",
    "df2 = pd.read_csv(\"bobe.csv\")\n",
    "df3 = pd.read_csv(\"community_clien.csv\")\n",
    "df4 = pd.read_csv(\"clien_comments.csv\")\n",
    "df5 = pd.read_csv(\"bobe_comments.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['keyword'] = \"\"\n",
    "df.append(df2.loc[2]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"community_clien.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"community_ddanzi.csv\")\n",
    "df1 = df1[df1['time'] > '2021-04-30'].reset_index(drop=True)\n",
    "df = pd.DataFrame()\n",
    "df['keyword'] = \"\"\n",
    "\n",
    "cnt = 0\n",
    "for i in range(len(df1)) :\n",
    "    if \"이재명\" in df1['title'][i] :\n",
    "        df = df.append(df1.loc[i]).reset_index(drop=True)\n",
    "        df['keyword'][cnt] = \"이재명\"\n",
    "        cnt += 1\n",
    "        \n",
    "    if \"이낙연\" in df1['title'][i] :\n",
    "        df = df.append(df1.loc[i]).reset_index(drop=True)\n",
    "        df['keyword'][cnt] = \"이낙연\"\n",
    "        cnt += 1\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df[['keyword', 'writer','content', 'title', 'time']]\n",
    "df11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df11)) :\n",
    "    \n",
    "    try :\n",
    "        len(df11['content'][i]) < 5 \n",
    "\n",
    "    except :\n",
    "        print(\"scout :\", df11['content'][i])\n",
    "        df11['content'][i] = df11['title'][i]\n",
    "df11       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df11 = df11[['keyword','writer', 'content','time']]\n",
    "df11.columns = ['keyword','user_name', 'user_text','date']\n",
    "df11.to_csv(\"ddanzi_keyword.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"community_ddanzi.csv\")\n",
    "df2 = pd.read_csv(\"bobe.csv\")\n",
    "df3 = pd.read_csv(\"community_clien.csv\")\n",
    "df4 = pd.read_csv(\"clien_comments.csv\")\n",
    "df5 = pd.read_csv(\"bobe_comments.csv\")\n",
    "df1 = df1.iloc[:,:8]\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns = ['domain', 'title', 'user_name', 'url', 'date', 'view_cnt', 'like_cnt', 'user_text']\n",
    "df1.dropna(inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.iloc[:,:8]\n",
    "df2.columns = ['domain', 'title', 'user_name', 'url', 'date', 'view_cnt', 'like_cnt', 'user_text']\n",
    "df2.dropna(inplace=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.iloc[:,:8]\n",
    "df3.columns = ['domain', 'title', 'user_name', 'url', 'date', 'view_cnt', 'like_cnt','user_text']\n",
    "df3.dropna(inplace=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.dropna(inplace=True)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.dropna(inplace=True)\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df00 = pd.concat([df1,df2,df3,df4,df5]).dropna(axis=1).sort_values(by='date').reset_index(drop=True)\n",
    "\n",
    "drop_index = []\n",
    "for i in range(len(df00)) :\n",
    "    if \"삭제된\" in df00['user_name'][i] :\n",
    "        drop_index.append(i)\n",
    "df00 = df00.iloc[:drop_index[0],:]\n",
    "df00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df01 = df00[df00['date'] > '2021-04-30']\n",
    "df02 = df00[df00['date'] <= '2021-04-30']\n",
    "df01.to_csv(\"community.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df02.to_csv('community.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df00.to_csv(\"community_01.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns = ['domain', 'title', 'user_name', 'url', 'date', 'view_cnt', 'like_cnt',\n",
    "       'user_text', 'com_cnt', 'com_user', 'com_text']\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('keyword_clien.csv').iloc[:,1:]\n",
    "df2 = pd.read_csv(\"keyword_bobe.csv\").iloc[:,1:]\n",
    "df3 = pd.read_csv(\"ddanzi_keyword.csv\").iloc[:,1:]\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.concat([df1.dropna(),df2.dropna(),df3.dropna()]).dropna(axis=1).sort_values(by='date').reset_index(drop=True)\n",
    "df4.to_csv(\"keyword_community.csv\", index=False)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.concat([df1, df2], axis=0).reset_index(drop=True)\n",
    "# df4.drop([''])\n",
    "df_new = pd.DataFrame()\n",
    "df_new['user_name'] = df5['user_name']\n",
    "df_new['date'] = df5['date']\n",
    "df_new['user_text'] = df5['user_text']\n",
    "df_new.sort_values('date', inplace=True)\n",
    "df_new = df_new.reset_index(drop=True)\n",
    "df_new\n",
    "\n",
    "df_new.to_csv(\"./preprocessing/community_ddan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"2021.04.26-2021.04.29_naver.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['domain', 'keyword', 'user_text', 'channel', 'date']\n",
    "df.to_csv(\"naver.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = ['domain', 'keyword', 'user_text', 'channel', 'date', 'view']\n",
    "df.to_csv(\"youtube.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"./community_keyword.csv\")\n",
    "df2 = pd.read_csv(\"./ddanzidang.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1\n",
    "df4 = df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df1)) :\n",
    "    if df1['date'][i].strip()[:4] == \"2021\" :\n",
    "        df1['date'][i] = df1['date'][i].strip()[:10]\n",
    "    else :\n",
    "        df1['date'][i] = \"2021-04-28\"\n",
    "df1.sort_values('date', inplace=True)\n",
    "df1 = df1.reset_index(drop=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df2)) :\n",
    "    if df2['date'][i].strip()[:4] == \"2021\" :\n",
    "        df2['date'][i] = df2['date'][i].strip()[:10]\n",
    "    else :\n",
    "        df2['date'][i] = \"2021-04-28\"\n",
    "df2.sort_values('date', inplace=True)\n",
    "df2 = df2.reset_index(drop=True)\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['date'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_csv(\"./preprocessing/community_keyword_pre.csv\", index=False)\n",
    "df2.to_csv(\"./preprocessing/ddanzidang_pre.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(\"ddanzi_pre.csv\")\n",
    "df2 = pd.read_csv(\"clien_pre.csv\")\n",
    "df3 = pd.read_csv(\"bbombbu_pre.csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df1.append(df2).append(df3)\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.sort_values('date', inplace=True)\n",
    "df4.drop_duplicates()\n",
    "df4.reset_index(drop=True, inplace=True)\n",
    "df4.to_csv(\"community.csv\", index=False, encoding='utf-8-sig')\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv(\"twitter.csv\")\n",
    "df2 = pd.read_csv(\"twitter (1).csv\")\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df1.append(df2)\n",
    "df3.reset_index(drop=True, inplace=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3.to_csv('twitter.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.read_csv(\"news.csv\")\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df3[df3['keyword']==\"이재명\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df3[df3['keyword']==\"이낙연\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df3[df3['keyword']==\"정세균\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "file_list = glob(\"./*_com.csv\")\n",
    "file_list = file_list[:-1]\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for file in file_list :\n",
    "    df1 = pd.read_csv(file)\n",
    "    df = df.append(df1)\n",
    "    \n",
    "df.sort_values('date', inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop_duplicates()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.to_csv(\"community.csv\", index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df2[df2['keyword'] == \"이재명\"]), len(df2[df2['keyword'] == \"이낙연\"]), len(df2[df2['keyword'] == \"정세균\"]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
